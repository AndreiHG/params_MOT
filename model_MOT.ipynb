{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative model for MOT images\n",
    "## Team: Loic Anderegg, Daniel Ang, Andrei Gheorghe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high level objective of this project is to get the temperature of a gas of molecules or atoms trapped in a magneto-optical trap (MOT). For this, the first goal is to fit images of the MOT taken on a CCD camera to 2D Gaussians, which is our basic guess for its shape. On top of shape we also model multiple sources of uncertainty, from statistical uncertainty in our 2D Gaussian guess to uncertainties arising from shot noise, readout noise or scattered light noise. \n",
    "\n",
    "To actually get the temperature of the gas we physically have to release the molecules/atoms from the trap and let them expand. From the expansion rate we can then infer the temeprature. Thus, the second goal is to analyze multiple such images taken at different times after the release from the trap. For each moment in time we use our model to fit parameters such as $\\sigma_{\\mathrm{x}}$ and $\\sigma_{\\mathrm{y}}$, i.e. the widths of the MOT, which we then use to obtain the temperature.\n",
    "\n",
    "Ideally the package should be flexible enough to be used on any MOT image. Members from our group have data for MOTs made from molecules of CaF, or from atoms of Rb or K. We build our package by first testing it on the molecular MOT, since that is the one with the lowesr SNR and it also lends itself to expansions of the model such as considering the slosh of particles in the trap itself, which is not negligible in this case (in other words all trapped molecules have a non negligible initial velocity in the same direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import emcee\n",
    "\n",
    "import csv\n",
    "\n",
    "from io_package import *\n",
    "from params_MOT import MOT_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bare model\n",
    "\n",
    "The model is represented by a 2D Gaussian, with random peak amplitude, width and peak position.\n",
    "\n",
    "We thus start by defining the 2D and 1D Gaussian function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_2d(x, y, center_x, center_y, amplitude, sigma_x, sigma_y):\n",
    "    return amplitude*np.exp(-(x-center_x)/(2*sigma_x**2))*np.exp(-(y-center_y)/(2*sigma_y**2))\n",
    "\n",
    "def gaussian_1d(z, center_z, sigma_z, amplitude):\n",
    "    return amplitude*np.exp(-(z-center_z)**2/(2*sigma_z**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Image_with_CCD_readout_charge(image, readout_charge):\n",
    "    charge=(np.cumsum(image[::-1],axis=0)/readout_charge)\n",
    "    return image + charge[::-1]\n",
    "\n",
    "def MOT_bare_model(x, y, theta):\n",
    "    center_x, center_y, amplitude, sigma_x, sigma_y, background_offset, sigma_m, sigma_g = theta\n",
    "    return gaussian_2d(x, y, center_x, center_y, amplitude, sigma_x, sigma_y) + background_offset\n",
    "\n",
    "def MOT_model(x, y, theta):\n",
    "    # Use 40 for the readout_charge for now\n",
    "    return Image_with_CCD_readout_charge(MOT_bare_model(x, y, theta), 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of how a generic image generated with this model looks like, look at model_MOTonly.ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Uncertainties\n",
    "\n",
    "We consider three possible uncertainty sources:\n",
    "\n",
    "- a Gaussian statistical uncertainty in the model, $\\epsilon_{\\mathrm{i}}$;\n",
    "- a Poissonian uncertainty, given by shot noise in the CCD camera;\n",
    "- a Poissonian uncertainty, given by scattered light;\n",
    "- a Gaussian uncertainty with a prior that is proportionally higher if the pixels below it are brighter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Likelihood function\n",
    "\n",
    "To construct the likelihood function we need to consider all the uncertainties. Thus, each data point is given by: \n",
    "\n",
    "$$y_{\\mathrm{i}} = z_{\\mathrm{i}} + e_{\\mathrm{i}} = m(x_{\\mathrm{i}}, \\theta) + \\epsilon_{\\mathrm{i}} + f_{\\mathrm{i}} + g_{\\mathrm{i}} + sct_{\\mathrm{i}},$$\n",
    "\n",
    "where $m(x_{\\mathrm{i}}, \\theta)$ is the model data and $\\theta$ the set of parameters that go into the data.\n",
    "\n",
    "Following the methods of Gregory 4.8, we have the probability distribution for the proposition $Z_i$ that the model we considered gives for the $i$-th data point values in the range $z_{\\mathrm{i}}$ to $z_{\\mathrm{i}} + dz_{\\mathrm{i}}$:\n",
    "\n",
    "$$p(Z_{\\mathrm{i}}|M, \\theta, I) = f_{\\mathrm{Z}}(z_{\\mathrm{i}}) = \\frac{1}{\\sqrt{2 \\pi}\\sigma_{\\mathrm{mi}}} exp \\left( \\frac{- \\epsilon_i}{2 \\sigma_{\\mathrm{mi}}} \\right)$$.\n",
    "\n",
    "Note that for simplicity we will consider $\\epsilon_{\\mathrm{i}} = \\epsilon$ and $\\sigma_{\\mathrm{mi}} = \\sigma_{\\mathrm{m}}$, for all $i$.\n",
    "\n",
    "Next the shot noise component is given by:\n",
    "\n",
    "$$p(F_{\\mathrm{i}}|M, \\theta, I)  = e^{-\\mu_fi} \\frac{\\mu_{\\mathrm{fi}}^n}{n!}.$$\n",
    "\n",
    "A similar expression applies to the scattered light noise, with expected photon number $\\mu_{\\mathrm{scti}}$.\n",
    "\n",
    "Finally, include the readout noise. For now, only consider it as a simple Gaussian but can easily add a prior of the form sum(z(x0, y-i)), for $i$ from $0$ to $y0$, where (x0, y0) are the coordiantes of the pixel we are analyzing. Then the noise is really this Gaussian likelihood times the prior.\n",
    "\n",
    "$$p(G_{\\mathrm{i}}|M, \\theta, I) = \\frac{1}{\\sqrt{2 \\pi}\\sigma_{\\mathrm{gi}}} exp \\left( \\frac{- g_i}{2 \\sigma_{\\mathrm{gi}}} \\right)$$\n",
    "\n",
    "The likelihood for each pixel is then the convolution of the noise sources and the total likelihood is the product of all likelihoods for each pixel (so for log of the likelihood we perform a sum). For the first stages of the project we perform the convolution directly:\n",
    "\n",
    "NOTE: In this simple version of the model, the two Gaussian uncertainties convolve to a Gaussian with $\\sigma = \\sigma_{\\mathrm{m}} + \\sigma_{\\mathrm{g}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(theta, x, y, data):\n",
    "    '''\n",
    "    x, y: independent data (arrays of size 50)\n",
    "    data: measurements (brightness of pixel) \n",
    "    sigma_m: uncertainty in the model chosen\n",
    "    sigma_g: uncertainty from scattered light background\n",
    "    theta: model parameters\n",
    "    '''\n",
    "    center_x, center_y, amplitude, sigma_x, sigma_y, background_offset, sigma_m, sigma_g = theta\n",
    "      \n",
    "    #return -0.5*(np.sum((data[x-1][y-1] - MOT_model(x, y, theta))**2/(sigma_m**2 + sigma_g**2) + np.log(sigma_m**2 + sigma_g**2)))\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            return -0.5*(np.sum((data[int(i)-1][int(j)-1] - MOT_model(x, y, theta))**2/(sigma_m**2 + sigma_g**2) + np.log(sigma_m**2 + sigma_g**2)))\n",
    "    \n",
    "def log_prior(theta):\n",
    "    \"\"\"\n",
    "    returns log of prior probability distribution\n",
    "    \n",
    "    Parameters:\n",
    "        theta: model parameters (specified as a tuple)\n",
    "    \"\"\"\n",
    "    # unpack the model parameters\n",
    "    center_x, center_y, amplitude, sigma_x, sigma_y, background_offset, sigma_m, sigma_g = theta\n",
    "  \n",
    "    # impose bounds on parameters\n",
    "    # For now (the model data) impose strong bounds\n",
    "    if center_x > 30 or center_x < 20:\n",
    "        return -math.inf\n",
    "    if center_y > 30 or center_y < 20:\n",
    "        return -math.inf\n",
    "    if amplitude > 450 or amplitude < 350:\n",
    "        return -math.inf\n",
    "    if sigma_x > 8 or sigma_x < 5:\n",
    "        return -math.inf\n",
    "    if sigma_y > 8 or sigma_y < 3:\n",
    "        return -math.inf\n",
    "    if sigma_m < 0: \n",
    "        return -math.inf\n",
    "    if sigma_g < 0:\n",
    "        return -math.inf\n",
    "    if background_offset > 1000:\n",
    "        return -math.inf\n",
    "    \n",
    "    sigma_sigma_m_Jeff_prior = 1/(sigma_m) \n",
    "    sigma_sigma_g_Jeff_prior = 1/(sigma_g)\n",
    " \n",
    "    sigma_x_prior = 100/(50/7.5 - sigma_x)**2\n",
    "    sigma_y_prior = 100/(50/9 - sigma_y)**2\n",
    "    \n",
    "    # Use a pretty strong prior on the sigma_x and sigma_y values (for now)\n",
    "    if math.isnan(sigma_x_prior) or math.isnan(sigma_y_prior):\n",
    "        return 0 + np.log(sigma_sigma_m_Jeff_prior) + np.log(sigma_sigma_g_Jeff_prior)\n",
    "    else:\n",
    "        return 0 + np.log(sigma_sigma_m_Jeff_prior) + np.log(sigma_sigma_g_Jeff_prior) + np.log(sigma_x_prior) + np.log(sigma_y_prior)\n",
    "    \n",
    "def log_posterior(theta, x, y, data):\n",
    "    '''\n",
    "    theta: model parameters\n",
    "    x, y: independent data (arrays of size 250)\n",
    "    z: measurement (brightness of pixel) \n",
    "    sigma_m: uncertainty in the model chosen\n",
    "    sigma_g: uncertainty from scattered light background\n",
    "    theta: model parameter\n",
    "    '''\n",
    "    \n",
    "    center_x, center_y, amplitude, sigma_x, sigma_y, background_offset, sigma_m, sigma_g = theta\n",
    "    \n",
    "    return log_prior(theta) + log_likelihood(theta, x, y, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sampler (data, ndim, nwalkers, nsteps):\n",
    "    \n",
    "    # Set up the data\n",
    "    x = np.linspace(1, image_size, image_size)\n",
    "    y = np.linspace(1, image_size, image_size)\n",
    "    \n",
    "    ndim = ndim\n",
    "    nwalkers = nwalkers\n",
    "    nsteps = nsteps\n",
    "\n",
    "    #initial guess for center_x, center_y, amplitude, sigma_x, sigma_y, background_offset, sigma_m, sigma_g\n",
    "    ls_result = [25, 25, 400, 6.6667, 5.5556, 100, 20, 20] # from HBL figure 1 and randomly guessing\n",
    "    \n",
    "    starting_positions = [ls_result + 1e-1*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "    \n",
    "    # set up the sampler object\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=(x, y, data))\n",
    "    \n",
    "    # run the sampler. We use iPython's %time directive to tell us \n",
    "    # how long it took (in a script, you would leave out \"%time\")\n",
    "    %time sampler.run_mcmc(starting_positions, nsteps)\n",
    "    print('Done')\n",
    "    \n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-107c64217738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimage_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m# Try method of the class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mF:\\params_MOT_git\\params_MOT\\io_package.py\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(data, image_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mimage_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mMOT_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mF:\\params_MOT_git\\params_MOT\\params_MOT\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, image_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[1;31m#def __init__(self, data, time):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[1;31m#self.time = time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_sizes' is not defined"
     ]
    }
   ],
   "source": [
    "model_data_path = get_data_file_path('model_data.csv')\n",
    "model_data = load_data(data_file = model_data_path, delim = ' ')\n",
    "\n",
    "image_size = 50 \n",
    "\n",
    "image_object = load_image(model_data)\n",
    "\n",
    "# Try method of the class\n",
    "image_object.show(gauss_filter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emcce_sample = sampler (model_data, 8, 50, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initial guess for center_x, center_y, amplitude, sigma_x, sigma_y, background_offset, sigma_m, sigma_g\n",
    "\n",
    "fig, (ax_sigma_x, ax_sigma_y) = plt.subplots(2)\n",
    "ax_sigma_x.set(ylabel='sigma_x')\n",
    "ax_sigma_y.set(ylabel='sigma_y')\n",
    "for i in range(20):\n",
    "    sns.tsplot(emcce_sample.chain[i,:,3], ax=ax_sigma_x)\n",
    "    sns.tsplot(emcce_sample.chain[i,:,4], ax=ax_sigma_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Throw away first 1000 steps\n",
    "ndim = 8\n",
    "\n",
    "samples = emcce_sample.chain[:,1000:,:]\n",
    "traces = samples.reshape(-1, ndim).T\n",
    "\n",
    "parameter_samples = pd.DataFrame({'sigma_x': traces[3], 'sigma_y': traces[4]})\n",
    "\n",
    "q = parameter_samples.quantile([0.16,0.50,0.84], axis=0)\n",
    "sigma_x = q['sigma_x'][0.50]\n",
    "sigma_y = q['sigma_y'][0.50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(With the extremely trong priors) the fit is reasonable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
